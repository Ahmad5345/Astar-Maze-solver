{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVIRUXlVm4sX"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ContextLab/spam-classifier-llm-course/blob/main/Assignment2_SPAM_Classifier.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmYjgQrfm4sY"
      },
      "source": [
        "# Assignment 2: Advanced SPAM Classifier with Multi-Method Comparison\n",
        "\n",
        "**Course:** PSYC 51.17 - Models of Language and Communication  \n",
        "**Deadline:** January 26, 2026 at 11:59 PM EST\n",
        "\n",
        "---\n",
        "\n",
        "## Overview\n",
        "\n",
        "In this assignment, you will build a comprehensive spam classification system that implements multiple classification approaches, conducts rigorous comparative analysis, and performs extensive error analysis.\n",
        "\n",
        "Please refer to the [full assignment instructions](https://contextlab.github.io/llm-course/assignments/assignment-2/) for detailed requirements and grading rubric.\n",
        "\n",
        "---\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Setup and Data Loading](#setup)\n",
        "2. [Part 1: Classifier Implementations](#part1)\n",
        "3. [Part 2: Comprehensive Evaluation](#part2)\n",
        "4. [Part 3: Error Analysis](#part3)\n",
        "5. [Part 4: Adversarial Testing](#part4)\n",
        "6. [Part 5: Real-World Considerations](#part5)\n",
        "7. [Discussion and Reflection](#discussion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98EfQdu4m4sY"
      },
      "source": [
        "<a id='setup'></a>\n",
        "## 1. Setup and Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDzl2Crfm4sZ"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q transformers datasets scikit-learn pandas numpy matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJjICNTMm4sZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nhkkeEim4sZ"
      },
      "outputs": [],
      "source": [
        "# Download the training dataset\n",
        "dataset_url = 'https://raw.githubusercontent.com/ContextLab/spam-classifier-llm-course/main/training.zip'\n",
        "dataset_path = 'training.zip'\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "    print(\"Downloading dataset...\")\n",
        "    urllib.request.urlretrieve(dataset_url, dataset_path)\n",
        "    print(\"Download complete.\")\n",
        "else:\n",
        "    print(\"Dataset already exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvR2ocTWm4sZ"
      },
      "outputs": [],
      "source": [
        "def load_dataset(zip_path):\n",
        "    \"\"\"\n",
        "    Load emails from a zip archive containing spam/ and ham/ folders.\n",
        "\n",
        "    Returns:\n",
        "        emails: List of email texts\n",
        "        labels: List of labels (1 for spam, 0 for ham)\n",
        "    \"\"\"\n",
        "    # Extract if needed\n",
        "    dataset_dir = Path(zip_path).with_suffix('')\n",
        "    if not dataset_dir.exists():\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(dataset_dir)\n",
        "\n",
        "    emails = []\n",
        "    labels = []\n",
        "\n",
        "    # Load spam\n",
        "    spam_folder = dataset_dir / \"training/spam\"\n",
        "    for file_path in spam_folder.iterdir():\n",
        "        if file_path.is_file():\n",
        "            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "                emails.append(f.read())\n",
        "                labels.append(1)\n",
        "\n",
        "    # Load ham\n",
        "    ham_folder = dataset_dir / \"training/ham\"\n",
        "    for file_path in ham_folder.iterdir():\n",
        "        if file_path.is_file():\n",
        "            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "                emails.append(f.read())\n",
        "                labels.append(0)\n",
        "\n",
        "    return emails, labels\n",
        "\n",
        "emails, labels = load_dataset('training.zip')\n",
        "print(f\"Loaded {len(emails)} emails\")\n",
        "print(f\"Spam: {sum(labels)}, Ham: {len(labels) - sum(labels)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TcKH7izm4sZ"
      },
      "outputs": [],
      "source": [
        "# TODO: Split data into train/validation/test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# First split: train (70%) and temp (30%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    emails,\n",
        "    labels,\n",
        "    test_size=0.30,\n",
        "    random_state=42,\n",
        "    stratify=labels\n",
        ")\n",
        "\n",
        "# Second split: validation (15%) and test (15%)\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp,\n",
        "    y_temp,\n",
        "    test_size=0.50,\n",
        "    random_state=42,\n",
        "    stratify=y_temp\n",
        ")\n",
        "\n",
        "print(\"Dataset splits:\")\n",
        "print(f\"Train: {len(X_train)}\")\n",
        "print(f\"Validation: {len(X_val)}\")\n",
        "print(f\"Test: {len(X_test)}\")\n",
        "\n",
        "print(\"\\nClass distribution:\")\n",
        "print(f\"Train spam: {sum(y_train)}, ham: {len(y_train) - sum(y_train)}\")\n",
        "print(f\"Val spam: {sum(y_val)}, ham: {len(y_val) - sum(y_val)}\")\n",
        "print(f\"Test spam: {sum(y_test)}, ham: {len(y_test) - sum(y_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDhPgb6mm4sZ"
      },
      "source": [
        "<a id='part1'></a>\n",
        "## 2. Part 1: Multiple Classifier Implementations (40 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "596CsFbtm4sa"
      },
      "source": [
        "### 2.1 Traditional ML Baseline (15 points)\n",
        "\n",
        "Implement **two** traditional ML classifiers with TF-IDF features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8t5bVjtjm4sa"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# TODO: Implement TF-IDF vectorizer with appropriate parameters\n",
        "# Document your feature engineering choices\n",
        "\n",
        "vectorizer = TfidfVectorizer(\n",
        "    lowercase=True,            # Normalize casing (e.g., \"FREE\" vs \"free\")\n",
        "    stop_words='english',      # Remove common function words with low signal\n",
        "    ngram_range=(1, 2),        # Unigrams + bigrams capture short spam phrases\n",
        "    min_df=2,                  # Remove extremely rare tokens (noise)\n",
        "    max_df=0.95,               # Remove near-constant terms\n",
        "    sublinear_tf=True,         # Log-scaled term frequency (robust to long emails)\n",
        "    norm='l2'                  # Required for linear SVM geometry\n",
        ")\n",
        "\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_val_tfidf = vectorizer.transform(X_val)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "print(\"TF-IDF shapes:\")\n",
        "print(\"Train:\", X_train_tfidf.shape)\n",
        "print(\"Val:\", X_val_tfidf.shape)\n",
        "print(\"Test:\", X_test_tfidf.shape)\n",
        "\n",
        "# TODO: Implement first traditional classifier\n",
        "classifier1 = MultinomialNB(\n",
        "    alpha=1.0   # Laplace smoothing for robustness to unseen tokens\n",
        ")\n",
        "classifier1.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# TODO: Implement second traditional classifier\n",
        "classifier2 = SVC(\n",
        "    kernel='linear',    # Linear kernel scales well for high-dimensional text\n",
        "    C=1.0,              # Regularization strength\n",
        "    probability=True,   # Enables ROC/AUC evaluation\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "classifier2.fit(X_train_tfidf, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Traditional model predictions\n",
        "# -------------------------\n",
        "nb_preds = classifier1.predict(X_test_tfidf)\n",
        "svm_preds = classifier2.predict(X_test_tfidf)\n"
      ],
      "metadata": {
        "id": "hpM537pBzG_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08L2XJXUm4sa"
      },
      "source": [
        "### 2.2 Neural/Transformer-Based Model (15 points)\n",
        "\n",
        "Implement a transformer-based classifier (BERT, DistilBERT, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3XOJG-pm4sa"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# -------------------\n",
        "# Check for GPU\n",
        "# -------------------\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# -------------------------\n",
        "# Load pre-trained model\n",
        "# -------------------------\n",
        "\n",
        "model_name = \"distilbert-base-uncased\"  # fast, strong baseline\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name,num_labels=2).to(device)\n",
        "\n",
        "# -------------------------\n",
        "# Prepare Hugging Face datasets\n",
        "# -------------------------\n",
        "\n",
        "train_dataset = Dataset.from_dict({\"text\": X_train,\"label\": y_train})\n",
        "val_dataset = Dataset.from_dict({\"text\": X_val,\"label\": y_val})\n",
        "test_dataset = Dataset.from_dict({\"text\": X_test,\"label\": y_test})\n",
        "\n",
        "# -------------------------\n",
        "# Tokenization\n",
        "# -------------------------\n",
        "\n",
        "def tokenize_function(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set PyTorch format\n",
        "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Metrics\n",
        "# -------------------------\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = logits.argmax(axis=1)\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc,\"precision\": precision,\"recall\": recall,\"f1\": f1}\n",
        "\n",
        "# -------------------------\n",
        "# Training configuration\n",
        "# -------------------------\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "# -------------------------\n",
        "# Trainer\n",
        "# -------------------------\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Fine-tune the model\n",
        "# -------------------------\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "aoOYX3LQzxge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Traditional model probabilities\n",
        "# -------------------------\n",
        "\n",
        "# Multinomial Naive Bayes probabilities\n",
        "nb_probs = classifier1.predict_proba(X_test_tfidf)[:, 1]\n",
        "\n",
        "# Linear SVM probabilities\n",
        "svm_probs = classifier2.predict_proba(X_test_tfidf)[:, 1]"
      ],
      "metadata": {
        "id": "hA9hiycK-XcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Transformer probabilities\n",
        "# -------------------------\n",
        "\n",
        "predictions = trainer.predict(test_dataset)\n",
        "bert_logits = predictions.predictions\n",
        "bert_probs = torch.softmax(torch.tensor(bert_logits), dim=1)[:, 1].numpy()"
      ],
      "metadata": {
        "id": "mc4YR54a0Aoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Transformer predictions\n",
        "# -------------------------\n",
        "bert_preds = np.argmax(bert_logits, axis=1)"
      ],
      "metadata": {
        "id": "JBc3ow_n0DAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMVvRmYLm4sa"
      },
      "source": [
        "### 2.3 Ensemble Method (10 points)\n",
        "\n",
        "Create an ensemble that combines your best models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTFgj9jom4sa"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement ensemble method (voting, stacking, or boosting)\n",
        "# Document your ensemble strategy\n",
        "\n",
        "# -------------------------\n",
        "# Soft voting ensemble\n",
        "# -------------------------\n",
        "\n",
        "ensemble_probs = (nb_probs + svm_probs + bert_probs) / 3\n",
        "ensemble_preds = (ensemble_probs >= 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRWXNhTam4sa"
      },
      "source": [
        "<a id='part2'></a>\n",
        "## 3. Part 2: Comprehensive Evaluation (25 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-fuh8CSm4sa"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score,\n",
        "    confusion_matrix, classification_report\n",
        ")\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "def evaluate_and_collect(\n",
        "    name,\n",
        "    y_true,\n",
        "    y_pred,\n",
        "    y_prob=None,\n",
        "    plot_cm=True,\n",
        "    verbose=True\n",
        "):\n",
        "    \"\"\"\n",
        "    Evaluate a classifier, optionally plot confusion matrix,\n",
        "    print reports, and return metrics as a dict.\n",
        "    \"\"\"\n",
        "\n",
        "    metrics = {\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"Precision\": precision_score(y_true, y_pred),\n",
        "        \"Recall\": recall_score(y_true, y_pred),\n",
        "        \"F1\": f1_score(y_true, y_pred),\n",
        "        \"AUC\": roc_auc_score(y_true, y_prob) if y_prob is not None else None\n",
        "    }\n",
        "\n",
        "    if verbose:\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "        print(f\"{name} Evaluation\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        for k, v in metrics.items():\n",
        "            if k != \"Model\" and v is not None:\n",
        "                print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(y_true, y_pred, target_names=[\"Ham\", \"Spam\"]))\n",
        "\n",
        "    if plot_cm:\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        plt.figure(figsize=(6, 5))\n",
        "        sns.heatmap(\n",
        "            cm,\n",
        "            annot=True,\n",
        "            fmt=\"d\",\n",
        "            cmap=\"Blues\",\n",
        "            xticklabels=[\"Ham\", \"Spam\"],\n",
        "            yticklabels=[\"Ham\", \"Spam\"]\n",
        "        )\n",
        "        plt.title(f\"{name} - Confusion Matrix\")\n",
        "        plt.ylabel(\"True Label\")\n",
        "        plt.xlabel(\"Predicted Label\")\n",
        "        plt.show()\n",
        "\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmmucnFym4sa"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "results.append(\n",
        "    evaluate_and_collect(\n",
        "        \"Naive Bayes (TF-IDF)\",\n",
        "        y_test,\n",
        "        nb_preds,\n",
        "        nb_probs\n",
        "    )\n",
        ")\n",
        "\n",
        "results.append(\n",
        "    evaluate_and_collect(\n",
        "        \"Linear SVM (TF-IDF)\",\n",
        "        y_test,\n",
        "        svm_preds,\n",
        "        svm_probs\n",
        "    )\n",
        ")\n",
        "\n",
        "results.append(\n",
        "    evaluate_and_collect(\n",
        "        \"DistilBERT\",\n",
        "        y_test,\n",
        "        bert_preds,\n",
        "        bert_probs\n",
        "    )\n",
        ")\n",
        "\n",
        "results.append(\n",
        "    evaluate_and_collect(\n",
        "        \"Ensemble (Soft Voting)\",\n",
        "        y_test,\n",
        "        ensemble_preds,\n",
        "        ensemble_probs\n",
        "    )\n",
        ")\n",
        "\n",
        "results_df = pd.DataFrame(results).set_index(\"Model\")\n",
        "display(results_df.round(4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhZgh7YSm4sa"
      },
      "outputs": [],
      "source": [
        "# TODO: Measure computational efficiency\n",
        "# Training time, inference time, model size, throughput\n",
        "import time\n",
        "\n",
        "def time_training(model, X, y):\n",
        "    start = time.time()\n",
        "    model.fit(X, y)\n",
        "    return time.time() - start\n",
        "\n",
        "nb_train_time = time_training(\n",
        "    MultinomialNB(alpha=1.0), X_train_tfidf, y_train\n",
        ")\n",
        "\n",
        "svm_train_time = time_training(\n",
        "    SVC(kernel=\"linear\", C=1.0), X_train_tfidf, y_train\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_train_time = trainer.state.log_history[-1][\"train_runtime\"]"
      ],
      "metadata": {
        "id": "9e4nckoO2hcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def time_inference(model, X):\n",
        "    start = time.time()\n",
        "    model.predict(X)\n",
        "    return time.time() - start\n",
        "\n",
        "nb_infer_time = time_inference(classifier1, X_test_tfidf)\n",
        "svm_infer_time = time_inference(classifier2, X_test_tfidf)\n",
        "\n",
        "start = time.time()\n",
        "trainer.predict(test_dataset)\n",
        "bert_infer_time = time.time() - start"
      ],
      "metadata": {
        "id": "PKfP_VLl2wz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "model_sizes = {\n",
        "    \"Naive Bayes\": sys.getsizeof(classifier1),\n",
        "    \"Linear SVM\": sys.getsizeof(classifier2),\n",
        "    \"DistilBERT\": sum(p.numel() for p in model.parameters()) * 4 / (1024**2)  # MB\n",
        "}\n",
        "\n",
        "model_sizes"
      ],
      "metadata": {
        "id": "gv45b2DQ2zW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "efficiency_df = pd.DataFrame({\n",
        "    \"Training Time (s)\": [nb_train_time, svm_train_time, bert_train_time],\n",
        "    \"Inference Time (s)\": [nb_infer_time, svm_infer_time, bert_infer_time],\n",
        "    \"Model Size\": [\"Small\", \"Medium\", f\"{model_sizes['DistilBERT']:.1f} MB\"]\n",
        "}, index=[\"Naive Bayes\", \"Linear SVM\", \"DistilBERT\"])\n",
        "\n",
        "display(efficiency_df)"
      ],
      "metadata": {
        "id": "EMtjz5v_21gY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEk1-GEEm4sa"
      },
      "outputs": [],
      "source": [
        "# TODO: Cross-validation with statistical significance testing\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "nb_pipeline = Pipeline([\n",
        "    (\"tfidf\", vectorizer),\n",
        "    (\"nb\", MultinomialNB(alpha=1.0))\n",
        "])\n",
        "\n",
        "svm_pipeline = Pipeline([\n",
        "    (\"tfidf\", vectorizer),\n",
        "    (\"svm\", SVC(kernel=\"linear\", C=1.0))\n",
        "])\n",
        "\n",
        "nb_f1 = cross_val_score(nb_pipeline, emails, labels, cv=5, scoring=\"f1\")\n",
        "svm_f1 = cross_val_score(svm_pipeline, emails, labels, cv=5, scoring=\"f1\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_rel\n",
        "\n",
        "t_stat, p_value = ttest_rel(nb_f1, svm_f1)\n",
        "\n",
        "print(f\"Paired t-test (NB vs SVM)\")\n",
        "print(f\"t-statistic: {t_stat:.4f}\")\n",
        "print(f\"p-value:     {p_value:.4e}\")"
      ],
      "metadata": {
        "id": "pXFNvTQa24PF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqorBTFgm4sa"
      },
      "source": [
        "<a id='part3'></a>\n",
        "## 4. Part 3: Error Analysis (20 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USkD3Lpzm4sa"
      },
      "outputs": [],
      "source": [
        "# TODO: Identify and analyze at least 20 misclassified emails\n",
        "# - 10 false positives (ham classified as spam)\n",
        "# - 10 false negatives (spam classified as ham)\n",
        "\n",
        "# Categorize errors and analyze patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzClCI25m4sa"
      },
      "outputs": [],
      "source": [
        "# TODO: Feature importance analysis\n",
        "# What words/patterns are most predictive?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUWsCmV1m4sa"
      },
      "source": [
        "<a id='part4'></a>\n",
        "## 5. Part 4: Adversarial Testing (10 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJLZNUW2m4sa"
      },
      "outputs": [],
      "source": [
        "# TODO: Create at least 5 adversarial emails\n",
        "# Test on all classifiers and analyze which are most robust\n",
        "\n",
        "adversarial_emails = [\n",
        "    # Example: spam trying to evade detection\n",
        "    \"\"\"Fr33 V1agra! Click here for amazing deals!\n",
        "\n",
        "    The weather today is quite nice. I hope you are doing well.\n",
        "    Best regards from a legitimate sender.\"\"\",\n",
        "\n",
        "    # Add more adversarial examples\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qigQIDuYm4sa"
      },
      "outputs": [],
      "source": [
        "# TODO: Test robustness against perturbations\n",
        "# - Typos and misspellings\n",
        "# - Case variations\n",
        "# - Synonym replacement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOKBa6n6m4sa"
      },
      "source": [
        "<a id='part5'></a>\n",
        "## 6. Part 5: Real-World Considerations (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG2Uxp4gm4sa"
      },
      "source": [
        "### Class Imbalance Discussion\n",
        "\n",
        "(How did you handle class imbalance? What happens if spam/ham ratio changes in production?)\n",
        "\n",
        "### Deployment Scenarios\n",
        "\n",
        "Which model would you choose for:\n",
        "- **Mobile email app** (fast inference, small size):\n",
        "- **Email server** (high throughput):\n",
        "- **Maximum accuracy** (no constraints):\n",
        "\n",
        "(Justify with evidence from your experiments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyZ6m9bEm4sb"
      },
      "source": [
        "<a id='discussion'></a>\n",
        "## 7. Discussion and Reflection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUHeOgChm4sb"
      },
      "source": [
        "### Key Findings\n",
        "\n",
        "(What did you learn about spam classification? Which approach worked best and why?)\n",
        "\n",
        "### Limitations\n",
        "\n",
        "(What are the limitations of your approach? What would you improve with more time?)\n",
        "\n",
        "### Reflection\n",
        "\n",
        "(What was challenging? What surprised you about the results?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLNZ9Uklm4sb"
      },
      "source": [
        "---\n",
        "\n",
        "## Submission Checklist\n",
        "\n",
        "- [ ] At least 3 classifiers implemented (2 traditional + 1 neural + ensemble)\n",
        "- [ ] All metrics computed and comparison table created\n",
        "- [ ] Cross-validation with statistical testing\n",
        "- [ ] At least 20 error cases analyzed\n",
        "- [ ] At least 5 adversarial examples created and tested\n",
        "- [ ] Deployment recommendations with justification\n",
        "- [ ] Discussion and reflection complete\n",
        "- [ ] Notebook runs without errors\n",
        "\n",
        "**To submit:** Commit and push this notebook to your GitHub repository before the deadline."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}